{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55608767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urządzenie: cuda\n",
      "Dane zostały pomyślnie wczytane.\n"
     ]
    }
   ],
   "source": [
    "# Importy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#  Wybór urządzenia\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Urządzenie: {device}\")\n",
    "\n",
    "# Transformacje danych (Tiny ImageNet 64x64 + normalizacja ImageNet)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Ścieżki do danych\n",
    "base_dir = '../tiny-imagenet-200'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "\n",
    "# Załaduj dane\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=os.path.join(val_dir, 'images'), transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"Dane zostały pomyślnie wczytane.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee24a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Funkcja do losowego wyświetlenia obrazu\n",
    "def show_random_image(data_loader, class_names):\n",
    "    images, labels = next(iter(data_loader))\n",
    "    idx = np.random.randint(0, len(images))\n",
    "    image, label = images[idx], labels[idx]\n",
    "\n",
    "    # Denormalizacja\n",
    "    image = image.permute(1, 2, 0).numpy()\n",
    "    image = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    image = np.clip(image, 0, 1)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Klasa: {class_names[label]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Lista nazw klas\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "# Podgląd\n",
    "show_random_image(train_loader, class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3a812",
   "metadata": {},
   "source": [
    "Definicja bazowego modelu (v1)\n",
    "Na podstawie wcześniejszych eksperymentów z trzema typami architektur (BalancedCNN, OverfittingCNN, UnderfittingCNN) zaprojektowano model, który łączy najważniejsze cechy korzystnych konfiguracji: umiarkowaną głębokość, stabilizację treningu oraz mechanizmy regularyzujące. Jego zadaniem jest osiągnięcie możliwie wysokiej dokładności przy zachowaniu stabilności procesu uczenia i zdolności do generalizacji.\n",
    "\n",
    "W niniejszej wersji bazowej zastosowano:\n",
    "\n",
    "6 warstw konwolucyjnych z progresywną liczbą filtrów (64 → 128 → 256),\n",
    "\n",
    "normalizację BatchNorm po każdej warstwie,\n",
    "\n",
    "funkcję aktywacji ReLU,\n",
    "\n",
    "warstwę MaxPool co kilka bloków konwolucyjnych,\n",
    "\n",
    "Dropout w warstwach w pełni połączonych (dla redukcji przeuczenia),\n",
    "\n",
    "strukturę FC zakończoną warstwą klasyfikacyjną dla 200 klas (Tiny ImageNet).\n",
    "\n",
    "Model będzie w kolejnych etapach modyfikowany i dostrajany w oparciu o metryki walidacyjne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f23e09af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FinalModelV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FinalModelV1, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Blok 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Blok 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Blok 3\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 16 * 16, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 200)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b8efe",
   "metadata": {},
   "source": [
    "Konfiguracja treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a30f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = FinalModelV1().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "num_epochs = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c1ed82",
   "metadata": {},
   "source": [
    "Pętla treningowa z walidacją i zapisem wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbbcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 5.4093, Train Acc: 0.0048, Val Loss: 5.2882, Val Acc: 0.0000\n",
      "Epoch 2/20 - Train Loss: 5.2993, Train Acc: 0.0045, Val Loss: 5.2915, Val Acc: 0.0000\n",
      "Epoch 3/20 - Train Loss: 5.2991, Train Acc: 0.0044, Val Loss: 5.3020, Val Acc: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 24\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     25\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "train_stats = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss /= total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss /= total\n",
    "    val_acc = correct / total\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    train_stats.append([epoch+1, train_loss, train_acc, val_loss, val_acc])\n",
    "\n",
    "    # Zapisywanie najlepszego modelu\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"final_model_best_v1.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a573e",
   "metadata": {},
   "source": [
    "Zapis metryk do CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad146345",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_stats, columns=[\"Epoch\", \"Train Loss\", \"Train Accuracy\", \"Validation Loss\", \"Validation Accuracy\"])\n",
    "df.to_csv(\"training_results_final_model_v1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc0efaa",
   "metadata": {},
   "source": [
    "Rysowanie wykresu przebiegu treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df[\"Epoch\"], df[\"Train Loss\"], label=\"Train Loss\")\n",
    "plt.plot(df[\"Epoch\"], df[\"Validation Loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss per Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df[\"Epoch\"], df[\"Train Accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(df[\"Epoch\"], df[\"Validation Accuracy\"], label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy per Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_progress_final_model_v1.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051b115",
   "metadata": {},
   "source": [
    "Classification Report + Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model.load_state_dict(torch.load(\"final_model_best_v1.pt\"))\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Zapis classification_report\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names, zero_division=0)\n",
    "with open(\"classification_report_final_model_v1.txt\", \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Macierz błędów\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, cmap=\"Blues\", xticklabels=False, yticklabels=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.savefig(\"confusion_matrix_final_model_v1.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b6138",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdef8100",
   "metadata": {},
   "source": [
    " poniżej znajduje się kompaktowa wersja finalnego modelu (v2) oparta na najlepszych wynikach oraz rozszerzona o sprawdzone mechanizmy. W tym podejściu uwzględniono:\n",
    "\n",
    "architekturę z progresywnym wzrostem liczby filtrów (64 → 128 → 256),\n",
    "\n",
    "BatchNorm i Dropout,\n",
    "\n",
    "optymalizator AdamW z weight decay,\n",
    "\n",
    "harmonogram uczenia (scheduler),\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b029ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model, trening, walidacja, zapis metryk i wykresów\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Konfiguracja\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transformacje\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dane\n",
    "base_dir = '../tiny-imagenet-200'\n",
    "val_dir='../tiny-imagenet-200/val'\n",
    "train_dataset = datasets.ImageFolder(os.path.join(base_dir, 'train'), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=os.path.join(val_dir, 'images'), transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "# Model\n",
    "class FinalModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FinalModelV2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 8 * 8, 512), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(512, 200)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "\n",
    "model = FinalModelV2().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96e17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Acc: 0.0060 | Val Acc: 0.0000\n",
      "Epoch 2/20 | Train Acc: 0.0073 | Val Acc: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 16\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     17\u001b[0m train_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (outputs\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     18\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#trening i walidacja\n",
    "num_epochs = 20\n",
    "best_loss = float('inf')\n",
    "stats = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss, train_correct, total = 0.0, 0, 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "        train_correct += (outputs.argmax(1) == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    train_loss /= total\n",
    "    train_acc = train_correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_correct = 0.0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "            val_correct += (outputs.argmax(1) == y).sum().item()\n",
    "            all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "    val_loss /= len(val_dataset)\n",
    "    val_acc = val_correct / len(val_dataset)\n",
    "    scheduler.step(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    stats.append([epoch+1, train_loss, train_acc, val_loss, val_acc])\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"final_model_best_v2.pt\")\n",
    "\n",
    "# Zapis wyników\n",
    "df = pd.DataFrame(stats, columns=[\"Epoch\", \"Train Loss\", \"Train Accuracy\", \"Val Loss\", \"Val Accuracy\"])\n",
    "df.to_csv(\"training_results_final_model_v2.csv\", index=False)\n",
    "\n",
    "# Wykres\n",
    "plt.plot(df[\"Epoch\"], df[\"Train Loss\"], label=\"Train Loss\")\n",
    "plt.plot(df[\"Epoch\"], df[\"Val Loss\"], label=\"Val Loss\")\n",
    "plt.plot(df[\"Epoch\"], df[\"Train Accuracy\"], label=\"Train Acc\")\n",
    "plt.plot(df[\"Epoch\"], df[\"Val Accuracy\"], label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.legend(); plt.tight_layout()\n",
    "plt.savefig(\"training_progress_final_model.png\"); plt.show()\n",
    "\n",
    "# Raport\n",
    "model.load_state_dict(torch.load(\"final_model_best_v2.pt\"))\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        outputs = model(x)\n",
    "        all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names, zero_division=0)\n",
    "with open(\"classification_report_final_model_v2.txt\", \"w\") as f:\n",
    "    f.write(report)\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "sns.heatmap(cm, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"confusion_matrix_final_model_v2.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b734d4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0ff1cbf",
   "metadata": {},
   "source": [
    "Co zawiera FinalModelV3:\n",
    "Głębszą architekturę (8 warstw konwolucyjnych) z przemyślanym podziałem bloków,\n",
    "\n",
    "Batch Normalization i ReLU w każdym bloku,\n",
    "\n",
    "Dropout w warstwach w pełni połączonych i na wyjściu bloku konwolucyjnego,\n",
    "\n",
    "Optymalizator AdamW z harmonogramem CosineAnnealingLR,\n",
    "\n",
    "EarlyStopping na podstawie walidacyjnego lossu (patience=5),\n",
    "\n",
    "20% augmentacji danych (obrót, losowe przycięcie),\n",
    "\n",
    "Dokładne logowanie: zapisywanie strat, dokładności, wykresów, raportu klasyfikacji, macierzy błędów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a4548cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np, pandas as pd, os\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((72, 72)),\n",
    "    transforms.RandomCrop(64),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "base = '../tiny-imagenet-200'\n",
    "train_ds = datasets.ImageFolder(os.path.join(base, 'train'), transform=transform_train)\n",
    "val_ds = datasets.ImageFolder(os.path.join(base, 'val'), transform=transform_val)\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_dl = DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=4)\n",
    "class_names = train_ds.classes\n",
    "\n",
    "class FinalModelV3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def conv_block(in_c, out_c): return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1), nn.BatchNorm2d(out_c), nn.ReLU())\n",
    "        self.features = nn.Sequential(\n",
    "            conv_block(3, 64), conv_block(64, 64), nn.MaxPool2d(2),\n",
    "            conv_block(64, 128), conv_block(128, 128), nn.MaxPool2d(2),\n",
    "            conv_block(128, 256), conv_block(256, 256), nn.Dropout(0.2), nn.MaxPool2d(2),\n",
    "            conv_block(256, 512), conv_block(512, 512), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 4 * 4, 1024), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(512, 200)\n",
    "        )\n",
    "    def forward(self, x): return self.classifier(self.features(x))\n",
    "\n",
    "model = FinalModelV3().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "early_patience = 5\n",
    "best_loss = float('inf')\n",
    "early_counter = 0\n",
    "log = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fd9ff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Train 0.012, Val 0.018, Val Loss 6.0650\n",
      "Ep 2: Train 0.020, Val 0.003, Val Loss 6.9510\n",
      "Ep 3: Train 0.039, Val 0.001, Val Loss 8.6990\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 12\u001b[0m tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m tr_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (out\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     14\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    tr_loss, tr_correct, total = 0, 0, 0\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss.item() * x.size(0)\n",
    "        tr_correct += (out.argmax(1) == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    tr_loss /= total\n",
    "    tr_acc = tr_correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_correct = 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "            val_correct += (out.argmax(1) == y).sum().item()\n",
    "            all_preds.extend(out.argmax(1).cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "    val_loss /= len(val_ds)\n",
    "    val_acc = val_correct / len(val_ds)\n",
    "    scheduler.step()\n",
    "\n",
    "    log.append([epoch+1, tr_loss, tr_acc, val_loss, val_acc])\n",
    "    print(f\"Ep {epoch+1}: Train {tr_acc:.3f}, Val {val_acc:.3f}, Val Loss {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"final_model_v3_best.pt\")\n",
    "        early_counter = 0\n",
    "    else:\n",
    "        early_counter += 1\n",
    "        if early_counter >= early_patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "# Metryki\n",
    "df = pd.DataFrame(log, columns=[\"Epoch\", \"Train Loss\", \"Train Acc\", \"Val Loss\", \"Val Acc\"])\n",
    "df.to_csv(\"training_results_final_model_v3.csv\", index=False)\n",
    "plt.plot(df[\"Epoch\"], df[\"Train Acc\"], label=\"Train Acc\")\n",
    "plt.plot(df[\"Epoch\"], df[\"Val Acc\"], label=\"Val Acc\")\n",
    "plt.plot(df[\"Epoch\"], df[\"Train Loss\"], label=\"Train Loss\")\n",
    "plt.plot(df[\"Epoch\"], df[\"Val Loss\"], label=\"Val Loss\")\n",
    "plt.legend(); plt.grid(); plt.savefig(\"training_progress_final_model_v3.png\"); plt.show()\n",
    "\n",
    "# Raport + macierz\n",
    "model.load_state_dict(torch.load(\"final_model_v3_best.pt\"))\n",
    "model.eval(); all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for x, y in val_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        all_preds.extend(out.argmax(1).cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names, zero_division=0)\n",
    "with open(\"classification_report_final_model_v3.txt\", \"w\") as f: f.write(report)\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, cmap=\"Blues\", xticklabels=False, yticklabels=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"confusion_matrix_final_model_v3.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867fc6c0",
   "metadata": {},
   "source": [
    "nowoczesny model CNN, który poradzi sobie z Tiny ImageNet – małym, ale wymagającym zbiorem. Użyjemy:\n",
    "\n",
    "Residual blocks (ResNet-style),\n",
    "\n",
    "Batch Normalization,\n",
    "\n",
    "Dropout,\n",
    "\n",
    "Global Average Pooling,\n",
    "\n",
    "Data augmentation (już masz, skoro używasz ImageFolder + transformacje),\n",
    "\n",
    "Oraz AdamW jako optymalizatora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0aae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=False):\n",
    "        super().__init__()\n",
    "        stride = 2 if downsample else 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.skip = nn.Sequential()\n",
    "        if downsample or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "        return F.relu(out)\n",
    "\n",
    "# Final CNN model\n",
    "class CNNv2(nn.Module):\n",
    "    def __init__(self, num_classes=200):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            ResidualBlock(64, 64),\n",
    "            ResidualBlock(64, 64)\n",
    "        )\n",
    "        self.stage2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128, downsample=True),\n",
    "            ResidualBlock(128, 128)\n",
    "        )\n",
    "        self.stage3 = nn.Sequential(\n",
    "            ResidualBlock(128, 256, downsample=True),\n",
    "            ResidualBlock(256, 256)\n",
    "        )\n",
    "        self.stage4 = nn.Sequential(\n",
    "            ResidualBlock(256, 512, downsample=True),\n",
    "            ResidualBlock(512, 512)\n",
    "        )\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e412943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on validation set\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {acc:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "# Przykład użycia\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNv2(num_classes=200).to(device)\n",
    "evaluate(model, val_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa68ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Parametry treningu\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# Przygotowanie modelu, optymalizatora i scheduler'a\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNv2(num_classes=200).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "# Funkcja treningowa\n",
    "def train(model, train_loader, val_loader):\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = 100 * correct / total\n",
    "        val_acc = evaluate(model, val_loader, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%, Val Acc={val_acc:.2f}%\")\n",
    "\n",
    "        # Zapis najlepszego modelu\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "    print(f\"Najlepsza dokładność walidacyjna: {best_acc:.2f}%\")\n",
    "\n",
    "# Wywołanie treningu\n",
    "train(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebdf34",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
