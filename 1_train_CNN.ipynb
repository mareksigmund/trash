{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urządzenie: cuda\n",
      "Dane zostały pomyślnie wczytane.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sprawdzenie dostępności GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Urządzenie: {device}\")\n",
    "\n",
    "# Transformacje danych\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Rozmiar zgodny z Tiny ImageNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Ścieżki do danych\n",
    "base_dir = '../tiny-imagenet-200'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "\n",
    "# Wczytanie danych\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"Dane zostały pomyślnie wczytane.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Funkcja do wyświetlenia losowego obrazu z zestawu danych\n",
    "def show_random_image(data_loader, class_names):\n",
    "    # Pobranie losowej partii danych\n",
    "    images, labels = next(iter(data_loader))\n",
    "    \n",
    "    # Wybór losowego indeksu\n",
    "    idx = np.random.randint(0, len(images))\n",
    "    image, label = images[idx], labels[idx]\n",
    "    \n",
    "    # Odwrócenie normalizacji dla poprawnej wizualizacji\n",
    "    image = image.permute(1, 2, 0).numpy() * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    image = np.clip(image, 0, 1)\n",
    "\n",
    "    # Wyświetlenie obrazu\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Klasa: {class_names[label]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Lista klas z katalogów (ImageFolder automatycznie tworzy class_to_idx)\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "# Wyświetlenie losowego obrazu\n",
    "show_random_image(train_loader, class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defincja modeli bazując na wynikach z poprzednich eksperymentów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Optymalny (Balanced Model)\n",
    "\n",
    "10 warstw konwolucyjnych – zgodnie z wcześniejszymi eksperymentami zapewnia najlepszy kompromis między złożonością a stabilnością.\n",
    "\n",
    "Filtry: 64 → 128 → 128 → 256 – progresywny wzrost liczby filtrów pozwala uchwycić coraz bardziej złożone cechy.\n",
    "\n",
    "Rozmiar filtrów: 3x3 – mniejsze filtry skutecznie wychwytują lokalne cechy.\n",
    "\n",
    "Batch Normalization: Zapewnia stabilność treningu i przyspiesza konwergencję.\n",
    "\n",
    "Dropout (0.4): Zmniejsza ryzyko przeuczenia.\n",
    "\n",
    "Optymalizator Adam: Dobrze sprawdził się w poprzednich testach przy learning rate = 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BalancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BalancedCNN, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),  # 64 filtrów, 3x3\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2),  # Pooling po 4 warstwach konwolucyjnych\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2)  # Ponownie pooling po kilku warstwach\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 16 * 16, 512),  # Dopasowane do rozmiaru danych po konwolucjach\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),  # Regularyzacja\n",
    "            nn.Linear(512, 200)  # 200 klas w zbiorze Tiny ImageNet\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: Słaby (Underfitting Model)\n",
    "3 warstwy konwolucyjne – eksperymenty wykazały, że zbyt mała liczba warstw ogranicza zdolność modelu do rozpoznawania złożonych cech.\n",
    "\n",
    "Filtry: 32 → 64 → 128 – mniejsza liczba filtrów ogranicza zdolność modelu do ekstrakcji cech.\n",
    "\n",
    "Rozmiar filtrów: 5x5 – większe filtry mniej efektywnie wychwytują subtelne wzorce.\n",
    "\n",
    "Brak Batch Normalization i Dropout – celowo pomijamy te mechanizmy, aby zwiększyć ryzyko niedouczenia.\n",
    "\n",
    "Optymalizator SGD: Wolniejszy proces uczenia jest celowym zabiegiem w tym przypadku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnderfittingCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UnderfittingCNN, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 200)  # 128 kanałów przy wyjściu i rozmiar 8x8 po poolingach\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: Przeuczony (Overfitting Model)\n",
    "20 warstw konwolucyjnych – eksperymenty pokazały, że bardzo głęboka architektura ma tendencję do przeuczenia.\n",
    "\n",
    "Filtry: 64 → 128 → 256 → 512 – duża liczba filtrów znacząco zwiększa liczbę parametrów.\n",
    "\n",
    "Batch Normalization: Pomaga utrzymać stabilność mimo dużej liczby warstw.\n",
    "\n",
    "Dropout (0.2): Celowo słabsza regularyzacja, aby model mógł łatwiej zapamiętywać dane.\n",
    "\n",
    "Optymalizator Adam: Używany z learning rate = 0.0001, aby uniknąć niestabilności przy bardzo głębokiej sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class OverfittingCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OverfittingCNN, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for i in range(20):\n",
    "            out_channels = min(64 * (2 ** (i // 5)), 512)\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            if i % 5 == 4:  # Pooling co 5 warstw\n",
    "                layers.append(nn.MaxPool2d(2))\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "\n",
    "        # Obliczenie dynamicznego rozmiaru po konwolucjach\n",
    "        self.flatten_dim = 512 * 4 * 4  # Rozmiar po konwolucjach: (512, 4, 4)\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.flatten_dim, 1024),  # Poprawione wejście\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 200)  # 200 klas w Tiny ImageNet\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperyment 1 – Analiza wpływu learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Hipotezy\n",
    "BalancedCNN – Jako najlepiej zbalansowany model, powinien działać stabilnie przy umiarkowanych wartościach (0.001 i 0.0001). Przy 0.1 może dojść do niestabilnych skoków funkcji straty.\n",
    "\n",
    "UnderfittingCNN – Ze względu na prostą architekturę, powinien działać względnie stabilnie nawet przy większych wartościach learning rate, ale może mieć problemy z dokładnością.\n",
    "\n",
    "OverfittingCNN – Przy zbyt dużym learning rate (0.1) model najprawdopodobniej będzie niestabilny, natomiast przy małych wartościach (0.0001 i 0.00001) może uzyskać bardzo wysoką dokładność kosztem długiego czasu treningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struktura folderów została przygotowana.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ustawienia eksperymentu\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001]  # Testowane wartości LR\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "# Foldery do zapisu wyników\n",
    "results_base_folder = '../results/experiment_1'\n",
    "os.makedirs(results_base_folder, exist_ok=True)\n",
    "\n",
    "# Tworzenie struktury folderów dla każdego modelu i wartości learning rate\n",
    "for model_name in ['BalancedCNN', 'UnderfittingCNN', 'OverfittingCNN']:\n",
    "    for lr in learning_rates:\n",
    "        folder_path = os.path.join(results_base_folder, f'{model_name}_lr_{lr}')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "print(\"Struktura folderów została przygotowana.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Funkcja treningowa\n",
    "def train_model(model, train_loader, val_loader, num_epochs, learning_rate, model_name, results_folder):\n",
    "    # Konfiguracja urządzenia\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Kryterium straty i optymalizator\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Listy do przechowywania wyników\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    epoch_times = []\n",
    "\n",
    "    # Pętla treningowa\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Walidacja\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Czas treningu jednej epoki\n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Zapis modelu po każdej epoce\n",
    "        torch.save(model.state_dict(), f'{results_folder}/model_epoch_{epoch+1}.pth')\n",
    "\n",
    "        # Zapis macierzy błędów\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig(f'{results_folder}/confusion_matrix_epoch_{epoch+1}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Zapis raportu klasyfikacji\n",
    "        report = classification_report(all_labels, all_preds, zero_division=1)\n",
    "        with open(f'{results_folder}/classification_report_epoch_{epoch+1}.txt', 'w') as f:\n",
    "            f.write(report)\n",
    "\n",
    "    # Zapis wyników do CSV\n",
    "    results = pd.DataFrame({\n",
    "        'Epoch': range(1, num_epochs + 1),\n",
    "        'Train Loss': train_losses,\n",
    "        'Train Accuracy': train_accuracies,\n",
    "        'Validation Loss': val_losses,\n",
    "        'Validation Accuracy': val_accuracies,\n",
    "        'Epoch Time': epoch_times\n",
    "    })\n",
    "    results.to_csv(f'{results_folder}/training_results.csv', index=False)\n",
    "\n",
    "    # Wykres przebiegu treningu\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{results_folder}/training_progress.png')\n",
    "    plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla BalancedCNN\n",
    "from copy import deepcopy\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "balanced_model = BalancedCNN()\n",
    "\n",
    "# Pętla po różnych wartościach learning rate\n",
    "for lr in learning_rates:\n",
    "    print(f'\\n🔵 Trening BalancedCNN z learning rate = {lr}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_1/BalancedCNN_lr_{lr}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(balanced_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_loader, val_loader, num_epochs, lr, 'BalancedCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla UnderfittingCNN\n",
    "underfitting_model = UnderfittingCNN()\n",
    "\n",
    "# Pętla po różnych wartościach learning rate\n",
    "for lr in learning_rates:\n",
    "    print(f'\\n🟠 Trening UnderfittingCNN z learning rate = {lr}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_1/UnderfittingCNN_lr_{lr}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(underfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_loader, val_loader, num_epochs, lr, 'UnderfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla OverfittingCNN\n",
    "overfitting_model = OverfittingCNN()\n",
    "\n",
    "# Pętla po różnych wartościach learning rate\n",
    "for lr in learning_rates:\n",
    "    print(f'\\n🔴 Trening OverfittingCNN z learning rate = {lr}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_1/OverfittingCNN_lr_{lr}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(overfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_loader, val_loader, num_epochs, lr, 'OverfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperyment 2 – Analiza wpływu batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipotezy\n",
    "BalancedCNN\n",
    "Małe batch size (np. 8, 32) mogą prowadzić do większej stabilności, ale wolniejszego treningu.\n",
    "Większe batch size (np. 128, 256) mogą przyspieszyć trening, ale ryzyko przeuczenia wzrośnie.\n",
    "\n",
    "UnderfittingCNN\n",
    "Większe batch size (np. 128, 256) mogą poprawić stabilność gradientów w prostym modelu, ale mogą nie zwiększyć znacząco dokładności.\n",
    "Małe batch size mogą prowadzić do niestabilnej konwergencji.\n",
    "\n",
    "OverfittingCNN\n",
    "Większe batch size mogą spowodować niestabilne gradienty w tym bardzo złożonym modelu.\n",
    "Małe batch size mogą być kluczowe, by uniknąć problemu z eksplodującymi gradientami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struktura folderów została przygotowana.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ustawienia eksperymentu\n",
    "batch_sizes = [8, 32, 64, 128, 256]  # Testowane wartości batch size\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001  # Stała wartość, aby wykluczyć wpływ innych zmiennych\n",
    "\n",
    "# Foldery do zapisu wyników\n",
    "results_base_folder = '../results/experiment_2'\n",
    "os.makedirs(results_base_folder, exist_ok=True)\n",
    "\n",
    "# Tworzenie struktury folderów dla każdego modelu i wartości batch size\n",
    "for model_name in ['BalancedCNN', 'UnderfittingCNN', 'OverfittingCNN']:\n",
    "    for bs in batch_sizes:\n",
    "        folder_path = os.path.join(results_base_folder, f'{model_name}_bs_{bs}')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "print(\"Struktura folderów została przygotowana.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Funkcja treningowa z dynamicznym batch size\n",
    "def train_model(model, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, model_name, results_folder):\n",
    "    # Konfiguracja urządzenia\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Dostosowanie DataLoader'ów z dynamicznym batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Kryterium straty i optymalizator\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Listy do przechowywania wyników\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    epoch_times = []\n",
    "\n",
    "    # Pętla treningowa\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Walidacja\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Czas treningu jednej epoki\n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Zapis modelu po każdej epoce\n",
    "        torch.save(model.state_dict(), f'{results_folder}/model_epoch_{epoch+1}.pth')\n",
    "\n",
    "        # Zapis macierzy błędów\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig(f'{results_folder}/confusion_matrix_epoch_{epoch+1}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Zapis raportu klasyfikacji\n",
    "        report = classification_report(all_labels, all_preds, zero_division=1)\n",
    "        with open(f'{results_folder}/classification_report_epoch_{epoch+1}.txt', 'w') as f:\n",
    "            f.write(report)\n",
    "\n",
    "    # Zapis wyników do CSV\n",
    "    results = pd.DataFrame({\n",
    "        'Epoch': range(1, num_epochs + 1),\n",
    "        'Train Loss': train_losses,\n",
    "        'Train Accuracy': train_accuracies,\n",
    "        'Validation Loss': val_losses,\n",
    "        'Validation Accuracy': val_accuracies,\n",
    "        'Epoch Time': epoch_times\n",
    "    })\n",
    "    results.to_csv(f'{results_folder}/training_results.csv', index=False)\n",
    "\n",
    "    # Wykres przebiegu treningu\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{results_folder}/training_progress.png')\n",
    "    plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "balanced_model = BalancedCNN()\n",
    "\n",
    "# Pętla po różnych wartościach batch size\n",
    "for bs in batch_sizes:\n",
    "    print(f'\\n🔵 Trening BalancedCNN z batch size = {bs}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_2/BalancedCNN_bs_{bs}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(balanced_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, bs, 'BalancedCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla UnderfittingCNN\n",
    "underfitting_model = UnderfittingCNN()\n",
    "\n",
    "# Pętla po różnych wartościach batch size\n",
    "for bs in batch_sizes:\n",
    "    print(f'\\n🟠 Trening UnderfittingCNN z batch size = {bs}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_2/UnderfittingCNN_bs_{bs}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(underfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, bs, 'UnderfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla OverfittingCNN\n",
    "overfitting_model = OverfittingCNN()\n",
    "\n",
    "# Pętla po różnych wartościach batch size\n",
    "for bs in batch_sizes:\n",
    "    print(f'\\n🔴 Trening OverfittingCNN z batch size = {bs}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_2/OverfittingCNN_bs_{bs}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(overfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, bs, 'OverfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperyment 3 – Porównanie optymalizatorów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BalancedCNN\n",
    "Adam lub RMSprop powinny zapewnić najlepszą równowagę między stabilnością a szybkością uczenia.\n",
    "SGD może działać poprawnie, ale wymaga optymalnego learning rate.\n",
    "\n",
    "UnderfittingCNN\n",
    "SGD lub Adagrad mogą być dobrym wyborem ze względu na prostą architekturę modelu.\n",
    "Adam może nieznacznie przyspieszyć trening, ale niekoniecznie poprawi końcowe wyniki.\n",
    "\n",
    "OverfittingCNN\n",
    "AdamW lub RMSprop mogą okazać się kluczowe, aby utrzymać stabilność gradientów w tym bardzo głębokim modelu.\n",
    "SGD może działać niestabilnie bez dodatkowych mechanizmów, takich jak momentum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struktura folderów została przygotowana.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ustawienia eksperymentu\n",
    "optimizers_to_test = ['Adam', 'SGD', 'RMSprop', 'Adagrad', 'AdamW']  # Testowane optymalizatory\n",
    "num_epochs = 20\n",
    "batch_size = 64  # Stała wartość batch size, aby uniknąć wpływu innych zmiennych\n",
    "learning_rate = 0.001  # Stała wartość learning rate\n",
    "\n",
    "# Foldery do zapisu wyników\n",
    "results_base_folder = '../results/experiment_3'\n",
    "os.makedirs(results_base_folder, exist_ok=True)\n",
    "\n",
    "# Tworzenie struktury folderów dla każdego modelu i optymalizatora\n",
    "for model_name in ['BalancedCNN', 'UnderfittingCNN', 'OverfittingCNN']:\n",
    "    for optimizer_name in optimizers_to_test:\n",
    "        folder_path = os.path.join(results_base_folder, f'{model_name}_{optimizer_name}')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "print(\"Struktura folderów została przygotowana.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Funkcja treningowa z dynamicznym wyborem optymalizatora\n",
    "def train_model(model, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, optimizer_name, model_name, results_folder):\n",
    "    # Konfiguracja urządzenia\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Dostosowanie DataLoader'ów\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Kryterium straty\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Wybór optymalizatora na podstawie argumentu\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name == 'Adagrad':\n",
    "        optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name == 'AdamW':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Nieznany optymalizator: {optimizer_name}\")\n",
    "\n",
    "    # Listy do przechowywania wyników\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    epoch_times = []\n",
    "\n",
    "    # Pętla treningowa\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Walidacja\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Czas treningu jednej epoki\n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        print(f'{model_name} - {optimizer_name} - Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Zapis modelu po każdej epoce\n",
    "        torch.save(model.state_dict(), f'{results_folder}/model_epoch_{epoch+1}.pth')\n",
    "\n",
    "        # Zapis macierzy błędów\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig(f'{results_folder}/confusion_matrix_epoch_{epoch+1}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Zapis raportu klasyfikacji\n",
    "        report = classification_report(all_labels, all_preds, zero_division=1)\n",
    "        with open(f'{results_folder}/classification_report_epoch_{epoch+1}.txt', 'w') as f:\n",
    "            f.write(report)\n",
    "\n",
    "    # Zapis wyników do CSV\n",
    "    results = pd.DataFrame({\n",
    "        'Epoch': range(1, num_epochs + 1),\n",
    "        'Train Loss': train_losses,\n",
    "        'Train Accuracy': train_accuracies,\n",
    "        'Validation Loss': val_losses,\n",
    "        'Validation Accuracy': val_accuracies,\n",
    "        'Epoch Time': epoch_times\n",
    "    })\n",
    "    results.to_csv(f'{results_folder}/training_results.csv', index=False)\n",
    "\n",
    "    # Wykres przebiegu treningu\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{results_folder}/training_progress.png')\n",
    "    plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "balanced_model = BalancedCNN()\n",
    "\n",
    "# Pętla po różnych optymalizatorach\n",
    "for optimizer_name in optimizers_to_test:\n",
    "    print(f'\\n🔵 Trening BalancedCNN z optymalizatorem = {optimizer_name}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_3/BalancedCNN_{optimizer_name}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(balanced_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, optimizer_name, 'BalancedCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla UnderfittingCNN\n",
    "underfitting_model = UnderfittingCNN()\n",
    "\n",
    "# Pętla po różnych optymalizatorach\n",
    "for optimizer_name in optimizers_to_test:\n",
    "    print(f'\\n🟠 Trening UnderfittingCNN z optymalizatorem = {optimizer_name}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_3/UnderfittingCNN_{optimizer_name}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(underfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, optimizer_name, 'UnderfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla OverfittingCNN\n",
    "overfitting_model = OverfittingCNN()\n",
    "\n",
    "# Pętla po różnych optymalizatorach\n",
    "for optimizer_name in optimizers_to_test:\n",
    "    print(f'\\n🔴 Trening OverfittingCNN z optymalizatorem = {optimizer_name}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_3/OverfittingCNN_{optimizer_name}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(overfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, optimizer_name, 'OverfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperyment 4 – Badanie różnych metod regularyzacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipotezy\n",
    "BalancedCNN\n",
    "Dropout i Batch Normalization powinny zapewnić dobrą równowagę między stabilnością a skutecznością.\n",
    "L2 Regularization może dodatkowo poprawić generalizację.\n",
    "\n",
    "UnderfittingCNN\n",
    "Batch Normalization powinno poprawić stabilność, natomiast Dropout może spowolnić konwergencję.\n",
    "Early Stopping może być skuteczne przy prostym modelu, gdyż ograniczy niepotrzebne epoki.\n",
    "\n",
    "OverfittingCNN\n",
    "Dropout oraz L2 Regularization będą kluczowe w redukcji przeuczenia.\n",
    "Batch Normalization oraz Layer Normalization mogą poprawić stabilność gradientów przy bardzo głębokiej architekturze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struktura folderów została przygotowana.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ustawienia eksperymentu\n",
    "regularization_methods = ['Dropout', 'BatchNorm', 'L2_Regularization', 'EarlyStopping', 'LayerNorm']\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "learning_rate = 0.001  # Stała wartość learning rate\n",
    "\n",
    "# Foldery do zapisu wyników\n",
    "results_base_folder = '../results/experiment_4'\n",
    "os.makedirs(results_base_folder, exist_ok=True)\n",
    "\n",
    "# Tworzenie struktury folderów dla każdego modelu i metody regularyzacji\n",
    "for model_name in ['BalancedCNN', 'UnderfittingCNN', 'OverfittingCNN']:\n",
    "    for reg_method in regularization_methods:\n",
    "        folder_path = os.path.join(results_base_folder, f'{model_name}_{reg_method}')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "print(\"Struktura folderów została przygotowana.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Funkcja treningowa z dynamicznym wyborem metody regularyzacji\n",
    "def train_model(model, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, reg_method, model_name, results_folder):\n",
    "    # Konfiguracja urządzenia\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Dostosowanie DataLoader'ów\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Kryterium straty\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optymalizator (Adam dla spójności z wcześniejszymi eksperymentami)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Dodanie regularyzacji do modelu na podstawie wyboru\n",
    "    if reg_method == 'Dropout':\n",
    "        model.fc_layers.add_module(\"Dropout\", nn.Dropout(0.4))\n",
    "    elif reg_method == 'BatchNorm':\n",
    "        for layer in model.conv_layers:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                model.conv_layers.add_module(f\"BatchNorm_{layer.out_channels}\", nn.BatchNorm2d(layer.out_channels))\n",
    "    elif reg_method == 'L2_Regularization':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    elif reg_method == 'EarlyStopping':\n",
    "        early_stopping = True\n",
    "        best_loss = float('inf')\n",
    "        patience = 3  # Wczesne zatrzymanie po 3 epokach bez poprawy\n",
    "        patience_counter = 0\n",
    "    elif reg_method == 'LayerNorm':\n",
    "        for layer in model.fc_layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                model.fc_layers.add_module(f\"LayerNorm_{layer.out_features}\", nn.LayerNorm(layer.out_features))\n",
    "    else:\n",
    "        raise ValueError(f\"Nieznana metoda regularyzacji: {reg_method}\")\n",
    "\n",
    "    # Listy do przechowywania wyników\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    epoch_times = []\n",
    "\n",
    "    # Pętla treningowa\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Walidacja\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Wczesne zatrzymanie (Early Stopping)\n",
    "        if reg_method == 'EarlyStopping':\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f'Wczesne zatrzymanie treningu po {epoch + 1} epokach.')\n",
    "                    break\n",
    "\n",
    "        # Czas treningu jednej epoki\n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        print(f'{model_name} - {reg_method} - Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Zapis modelu po każdej epoce\n",
    "        torch.save(model.state_dict(), f'{results_folder}/model_epoch_{epoch+1}.pth')\n",
    "\n",
    "        # Zapis macierzy błędów\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig(f'{results_folder}/confusion_matrix_epoch_{epoch+1}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Zapis raportu klasyfikacji\n",
    "        report = classification_report(all_labels, all_preds, zero_division=1)\n",
    "        with open(f'{results_folder}/classification_report_epoch_{epoch+1}.txt', 'w') as f:\n",
    "            f.write(report)\n",
    "\n",
    "    # Zapis wyników do CSV\n",
    "    results = pd.DataFrame({\n",
    "        'Epoch': range(1, num_epochs + 1),\n",
    "        'Train Loss': train_losses,\n",
    "        'Train Accuracy': train_accuracies,\n",
    "        'Validation Loss': val_losses,\n",
    "        'Validation Accuracy': val_accuracies,\n",
    "        'Epoch Time': epoch_times\n",
    "    })\n",
    "    results.to_csv(f'{results_folder}/training_results.csv', index=False)\n",
    "\n",
    "    # Wykres przebiegu treningu\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.title(f'{model_name} - {reg_method} - Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{results_folder}/training_progress.png')\n",
    "    plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "balanced_model = BalancedCNN()\n",
    "\n",
    "# Pętla po różnych metodach regularyzacji\n",
    "for reg_method in regularization_methods:\n",
    "    print(f'\\n🔵 Trening BalancedCNN z regularyzacją = {reg_method}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_4/BalancedCNN_{reg_method}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(balanced_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, reg_method, 'BalancedCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla UnderfittingCNN\n",
    "underfitting_model = UnderfittingCNN()\n",
    "\n",
    "# Pętla po różnych metodach regularyzacji\n",
    "for reg_method in regularization_methods:\n",
    "    print(f'\\n🟠 Trening UnderfittingCNN z regularyzacją = {reg_method}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_4/UnderfittingCNN_{reg_method}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(underfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, reg_method, 'UnderfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla OverfittingCNN\n",
    "overfitting_model = OverfittingCNN()\n",
    "\n",
    "# Pętla po różnych metodach regularyzacji\n",
    "for reg_method in regularization_methods:\n",
    "    print(f'\\n🔴 Trening OverfittingCNN z regularyzacją = {reg_method}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_4/OverfittingCNN_{reg_method}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(overfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, reg_method, 'OverfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperyment 5 – Analiza wpływu augmentacji danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BalancedCNN\n",
    "Random Crop i Random Flip powinny poprawić zdolność modelu do rozpoznawania danych wejściowych w różnych pozycjach.\n",
    "\n",
    "UnderfittingCNN\n",
    "Color Jitter i Gaussian Noise mogą poprawić odporność prostego modelu na zniekształcenia danych.\n",
    "\n",
    "OverfittingCNN\n",
    "Random Rotation oraz Random Crop mogą znacząco poprawić generalizację modelu, który ma tendencję do przeuczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struktura folderów została przygotowana.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ustawienia eksperymentu\n",
    "augmentation_methods = ['RandomCrop', 'RandomFlip', 'ColorJitter', 'GaussianNoise', 'RandomRotation']\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "learning_rate = 0.001  # Stała wartość learning rate\n",
    "\n",
    "# Foldery do zapisu wyników\n",
    "results_base_folder = '../results/experiment_5'\n",
    "os.makedirs(results_base_folder, exist_ok=True)\n",
    "\n",
    "# Tworzenie struktury folderów dla każdego modelu i techniki augmentacji\n",
    "for model_name in ['BalancedCNN', 'UnderfittingCNN', 'OverfittingCNN']:\n",
    "    for aug_method in augmentation_methods:\n",
    "        folder_path = os.path.join(results_base_folder, f'{model_name}_{aug_method}')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "print(\"Struktura folderów została przygotowana.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Funkcja augmentacji danych na podstawie wybranej metody\n",
    "def get_augmentation(aug_method):\n",
    "    if aug_method == 'RandomCrop':\n",
    "        return transforms.RandomCrop((56, 56))  # Przycięcie obrazu do 56x56 z losową lokalizacją\n",
    "    elif aug_method == 'RandomFlip':\n",
    "        return transforms.RandomHorizontalFlip(p=0.5)  # Losowe odbicie poziome\n",
    "    elif aug_method == 'ColorJitter':\n",
    "        return transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)  \n",
    "    elif aug_method == 'GaussianNoise':\n",
    "        return transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.05),  # Szum gaussowski\n",
    "            transforms.ToPILImage()\n",
    "        ])\n",
    "    elif aug_method == 'RandomRotation':\n",
    "        return transforms.RandomRotation(30)  # Losowy obrót o ±30°\n",
    "    else:\n",
    "        raise ValueError(f\"Nieznana metoda augmentacji: {aug_method}\")\n",
    "\n",
    "# Funkcja treningowa z dynamicznym wyborem augmentacji\n",
    "def train_model(model, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, aug_method, model_name, results_folder):\n",
    "    # Konfiguracja urządzenia\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Dostosowanie augmentacji do danych treningowych\n",
    "    train_transform = transforms.Compose([\n",
    "        get_augmentation(aug_method),\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Walidacja pozostaje bez augmentacji\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Stworzenie nowych zestawów danych z odpowiednimi transformacjami\n",
    "    train_dataset.transform = train_transform\n",
    "    val_dataset.transform = val_transform\n",
    "\n",
    "    # Dostosowanie DataLoader'ów\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Kryterium straty i optymalizator\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Listy do przechowywania wyników\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    epoch_times = []\n",
    "\n",
    "    # Pętla treningowa\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Walidacja\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Czas treningu jednej epoki\n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        print(f'{model_name} - {aug_method} - Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Zapis modelu po każdej epoce\n",
    "        torch.save(model.state_dict(), f'{results_folder}/model_epoch_{epoch+1}.pth')\n",
    "\n",
    "    # Zapis wyników do CSV\n",
    "    results = pd.DataFrame({\n",
    "        'Epoch': range(1, num_epochs + 1),\n",
    "        'Train Loss': train_losses,\n",
    "        'Train Accuracy': train_accuracies,\n",
    "        'Validation Loss': val_losses,\n",
    "        'Validation Accuracy': val_accuracies,\n",
    "        'Epoch Time': epoch_times\n",
    "    })\n",
    "    results.to_csv(f'{results_folder}/training_results.csv', index=False)\n",
    "\n",
    "    # Wykres przebiegu treningu\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.title(f'{model_name} - {aug_method} - Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{results_folder}/training_progress.png')\n",
    "    plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "balanced_model = BalancedCNN()\n",
    "\n",
    "# Pętla po różnych technikach augmentacji\n",
    "for aug_method in augmentation_methods:\n",
    "    print(f'\\n🔵 Trening BalancedCNN z augmentacją = {aug_method}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_5/BalancedCNN_{aug_method}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(balanced_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, aug_method, 'BalancedCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla UnderfittingCNN\n",
    "underfitting_model = UnderfittingCNN()\n",
    "\n",
    "# Pętla po różnych technikach augmentacji\n",
    "for aug_method in augmentation_methods:\n",
    "    print(f'\\n🟠 Trening UnderfittingCNN z augmentacją = {aug_method}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_5/UnderfittingCNN_{aug_method}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(underfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, aug_method, 'UnderfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla OverfittingCNN\n",
    "overfitting_model = OverfittingCNN()\n",
    "\n",
    "# Pętla po różnych technikach augmentacji\n",
    "for aug_method in augmentation_methods:\n",
    "    print(f'\\n🔴 Trening OverfittingCNN z augmentacją = {aug_method}')\n",
    "    \n",
    "    # Ścieżka zapisu wyników\n",
    "    results_folder = f'../results/experiment_5/OverfittingCNN_{aug_method}'\n",
    "    \n",
    "    # Kopia modelu dla uniknięcia nadpisania wag\n",
    "    model_copy = deepcopy(overfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, aug_method, 'OverfittingCNN', results_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
