{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UrzÄ…dzenie: cuda\n",
      "Dane zostaÅ‚y pomyÅ›lnie wczytane.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sprawdzenie dostÄ™pnoÅ›ci GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"UrzÄ…dzenie: {device}\")\n",
    "\n",
    "# Transformacje danych\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Rozmiar zgodny z Tiny ImageNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ÅšcieÅ¼ki do danych\n",
    "base_dir = '../tiny-imagenet-200'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "\n",
    "# Wczytanie danych\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"Dane zostaÅ‚y pomyÅ›lnie wczytane.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Funkcja do wyÅ›wietlenia losowego obrazu z zestawu danych\n",
    "def show_random_image(data_loader, class_names):\n",
    "    # Pobranie losowej partii danych\n",
    "    images, labels = next(iter(data_loader))\n",
    "    \n",
    "    # WybÃ³r losowego indeksu\n",
    "    idx = np.random.randint(0, len(images))\n",
    "    image, label = images[idx], labels[idx]\n",
    "    \n",
    "    # OdwrÃ³cenie normalizacji dla poprawnej wizualizacji\n",
    "    image = image.permute(1, 2, 0).numpy() * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    image = np.clip(image, 0, 1)\n",
    "\n",
    "    # WyÅ›wietlenie obrazu\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Klasa: {class_names[label]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Lista klas z katalogÃ³w (ImageFolder automatycznie tworzy class_to_idx)\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "# WyÅ›wietlenie losowego obrazu\n",
    "show_random_image(train_loader, class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defincja modeli bazujÄ…c na wynikach z poprzednich eksperymentÃ³w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Optymalny (Balanced Model)\n",
    "\n",
    "10 warstw konwolucyjnych â€“ zgodnie z wczeÅ›niejszymi eksperymentami zapewnia najlepszy kompromis miÄ™dzy zÅ‚oÅ¼onoÅ›ciÄ… a stabilnoÅ›ciÄ….\n",
    "\n",
    "Filtry: 64 â†’ 128 â†’ 128 â†’ 256 â€“ progresywny wzrost liczby filtrÃ³w pozwala uchwyciÄ‡ coraz bardziej zÅ‚oÅ¼one cechy.\n",
    "\n",
    "Rozmiar filtrÃ³w: 3x3 â€“ mniejsze filtry skutecznie wychwytujÄ… lokalne cechy.\n",
    "\n",
    "Batch Normalization: Zapewnia stabilnoÅ›Ä‡ treningu i przyspiesza konwergencjÄ™.\n",
    "\n",
    "Dropout (0.4): Zmniejsza ryzyko przeuczenia.\n",
    "\n",
    "Optymalizator Adam: Dobrze sprawdziÅ‚ siÄ™ w poprzednich testach przy learning rate = 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BalancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BalancedCNN, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),  # 64 filtrÃ³w, 3x3\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2),  # Pooling po 4 warstwach konwolucyjnych\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2)  # Ponownie pooling po kilku warstwach\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 16 * 16, 512),  # Dopasowane do rozmiaru danych po konwolucjach\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),  # Regularyzacja\n",
    "            nn.Linear(512, 200)  # 200 klas w zbiorze Tiny ImageNet\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: SÅ‚aby (Underfitting Model)\n",
    "3 warstwy konwolucyjne â€“ eksperymenty wykazaÅ‚y, Å¼e zbyt maÅ‚a liczba warstw ogranicza zdolnoÅ›Ä‡ modelu do rozpoznawania zÅ‚oÅ¼onych cech.\n",
    "\n",
    "Filtry: 32 â†’ 64 â†’ 128 â€“ mniejsza liczba filtrÃ³w ogranicza zdolnoÅ›Ä‡ modelu do ekstrakcji cech.\n",
    "\n",
    "Rozmiar filtrÃ³w: 5x5 â€“ wiÄ™ksze filtry mniej efektywnie wychwytujÄ… subtelne wzorce.\n",
    "\n",
    "Brak Batch Normalization i Dropout â€“ celowo pomijamy te mechanizmy, aby zwiÄ™kszyÄ‡ ryzyko niedouczenia.\n",
    "\n",
    "Optymalizator SGD: Wolniejszy proces uczenia jest celowym zabiegiem w tym przypadku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnderfittingCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UnderfittingCNN, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 200)  # 128 kanaÅ‚Ã³w przy wyjÅ›ciu i rozmiar 8x8 po poolingach\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: Przeuczony (Overfitting Model)\n",
    "20 warstw konwolucyjnych â€“ eksperymenty pokazaÅ‚y, Å¼e bardzo gÅ‚Ä™boka architektura ma tendencjÄ™ do przeuczenia.\n",
    "\n",
    "Filtry: 64 â†’ 128 â†’ 256 â†’ 512 â€“ duÅ¼a liczba filtrÃ³w znaczÄ…co zwiÄ™ksza liczbÄ™ parametrÃ³w.\n",
    "\n",
    "Batch Normalization: Pomaga utrzymaÄ‡ stabilnoÅ›Ä‡ mimo duÅ¼ej liczby warstw.\n",
    "\n",
    "Dropout (0.2): Celowo sÅ‚absza regularyzacja, aby model mÃ³gÅ‚ Å‚atwiej zapamiÄ™tywaÄ‡ dane.\n",
    "\n",
    "Optymalizator Adam: UÅ¼ywany z learning rate = 0.0001, aby uniknÄ…Ä‡ niestabilnoÅ›ci przy bardzo gÅ‚Ä™bokiej sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class OverfittingCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OverfittingCNN, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for i in range(20):\n",
    "            out_channels = min(64 * (2 ** (i // 5)), 512)\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            if i % 5 == 4:  # Pooling co 5 warstw\n",
    "                layers.append(nn.MaxPool2d(2))\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "\n",
    "        # Obliczenie dynamicznego rozmiaru po konwolucjach\n",
    "        self.flatten_dim = 512 * 4 * 4  # Rozmiar po konwolucjach: (512, 4, 4)\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.flatten_dim, 1024),  # Poprawione wejÅ›cie\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 200)  # 200 klas w Tiny ImageNet\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperyment 1 â€“ Analiza wpÅ‚ywu learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Hipotezy\n",
    "BalancedCNN â€“ Jako najlepiej zbalansowany model, powinien dziaÅ‚aÄ‡ stabilnie przy umiarkowanych wartoÅ›ciach (0.001 i 0.0001). Przy 0.1 moÅ¼e dojÅ›Ä‡ do niestabilnych skokÃ³w funkcji straty.\n",
    "\n",
    "UnderfittingCNN â€“ Ze wzglÄ™du na prostÄ… architekturÄ™, powinien dziaÅ‚aÄ‡ wzglÄ™dnie stabilnie nawet przy wiÄ™kszych wartoÅ›ciach learning rate, ale moÅ¼e mieÄ‡ problemy z dokÅ‚adnoÅ›ciÄ….\n",
    "\n",
    "OverfittingCNN â€“ Przy zbyt duÅ¼ym learning rate (0.1) model najprawdopodobniej bÄ™dzie niestabilny, natomiast przy maÅ‚ych wartoÅ›ciach (0.0001 i 0.00001) moÅ¼e uzyskaÄ‡ bardzo wysokÄ… dokÅ‚adnoÅ›Ä‡ kosztem dÅ‚ugiego czasu treningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struktura folderÃ³w zostaÅ‚a przygotowana.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ustawienia eksperymentu\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001]  # Testowane wartoÅ›ci LR\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "# Foldery do zapisu wynikÃ³w\n",
    "results_base_folder = '../results/experiment_1'\n",
    "os.makedirs(results_base_folder, exist_ok=True)\n",
    "\n",
    "# Tworzenie struktury folderÃ³w dla kaÅ¼dego modelu i wartoÅ›ci learning rate\n",
    "for model_name in ['BalancedCNN', 'UnderfittingCNN', 'OverfittingCNN']:\n",
    "    for lr in learning_rates:\n",
    "        folder_path = os.path.join(results_base_folder, f'{model_name}_lr_{lr}')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "print(\"Struktura folderÃ³w zostaÅ‚a przygotowana.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Funkcja treningowa\n",
    "def train_model(model, train_loader, val_loader, num_epochs, learning_rate, model_name, results_folder):\n",
    "    # Konfiguracja urzÄ…dzenia\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Kryterium straty i optymalizator\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Listy do przechowywania wynikÃ³w\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    epoch_times = []\n",
    "\n",
    "    # PÄ™tla treningowa\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Walidacja\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Czas treningu jednej epoki\n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Zapis modelu po kaÅ¼dej epoce\n",
    "        torch.save(model.state_dict(), f'{results_folder}/model_epoch_{epoch+1}.pth')\n",
    "\n",
    "        # Zapis macierzy bÅ‚Ä™dÃ³w\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig(f'{results_folder}/confusion_matrix_epoch_{epoch+1}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Zapis raportu klasyfikacji\n",
    "        report = classification_report(all_labels, all_preds, zero_division=1)\n",
    "        with open(f'{results_folder}/classification_report_epoch_{epoch+1}.txt', 'w') as f:\n",
    "            f.write(report)\n",
    "\n",
    "    # Zapis wynikÃ³w do CSV\n",
    "    results = pd.DataFrame({\n",
    "        'Epoch': range(1, num_epochs + 1),\n",
    "        'Train Loss': train_losses,\n",
    "        'Train Accuracy': train_accuracies,\n",
    "        'Validation Loss': val_losses,\n",
    "        'Validation Accuracy': val_accuracies,\n",
    "        'Epoch Time': epoch_times\n",
    "    })\n",
    "    results.to_csv(f'{results_folder}/training_results.csv', index=False)\n",
    "\n",
    "    # Wykres przebiegu treningu\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{results_folder}/training_progress.png')\n",
    "    plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla BalancedCNN\n",
    "from copy import deepcopy\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "balanced_model = BalancedCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych wartoÅ›ciach learning rate\n",
    "for lr in learning_rates:\n",
    "    print(f'\\nðŸ”µ Trening BalancedCNN z learning rate = {lr}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_1/BalancedCNN_lr_{lr}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(balanced_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_loader, val_loader, num_epochs, lr, 'BalancedCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla UnderfittingCNN\n",
    "underfitting_model = UnderfittingCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych wartoÅ›ciach learning rate\n",
    "for lr in learning_rates:\n",
    "    print(f'\\nðŸŸ  Trening UnderfittingCNN z learning rate = {lr}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_1/UnderfittingCNN_lr_{lr}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(underfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_loader, val_loader, num_epochs, lr, 'UnderfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla OverfittingCNN\n",
    "overfitting_model = OverfittingCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych wartoÅ›ciach learning rate\n",
    "for lr in learning_rates:\n",
    "    print(f'\\nðŸ”´ Trening OverfittingCNN z learning rate = {lr}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_1/OverfittingCNN_lr_{lr}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(overfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_loader, val_loader, num_epochs, lr, 'OverfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperyment 2 â€“ Analiza wpÅ‚ywu batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipotezy\n",
    "BalancedCNN\n",
    "MaÅ‚e batch size (np. 8, 32) mogÄ… prowadziÄ‡ do wiÄ™kszej stabilnoÅ›ci, ale wolniejszego treningu.\n",
    "WiÄ™ksze batch size (np. 128, 256) mogÄ… przyspieszyÄ‡ trening, ale ryzyko przeuczenia wzroÅ›nie.\n",
    "\n",
    "UnderfittingCNN\n",
    "WiÄ™ksze batch size (np. 128, 256) mogÄ… poprawiÄ‡ stabilnoÅ›Ä‡ gradientÃ³w w prostym modelu, ale mogÄ… nie zwiÄ™kszyÄ‡ znaczÄ…co dokÅ‚adnoÅ›ci.\n",
    "MaÅ‚e batch size mogÄ… prowadziÄ‡ do niestabilnej konwergencji.\n",
    "\n",
    "OverfittingCNN\n",
    "WiÄ™ksze batch size mogÄ… spowodowaÄ‡ niestabilne gradienty w tym bardzo zÅ‚oÅ¼onym modelu.\n",
    "MaÅ‚e batch size mogÄ… byÄ‡ kluczowe, by uniknÄ…Ä‡ problemu z eksplodujÄ…cymi gradientami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struktura folderÃ³w zostaÅ‚a przygotowana.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ustawienia eksperymentu\n",
    "batch_sizes = [8, 32, 64, 128, 256]  # Testowane wartoÅ›ci batch size\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001  # StaÅ‚a wartoÅ›Ä‡, aby wykluczyÄ‡ wpÅ‚yw innych zmiennych\n",
    "\n",
    "# Foldery do zapisu wynikÃ³w\n",
    "results_base_folder = '../results/experiment_2'\n",
    "os.makedirs(results_base_folder, exist_ok=True)\n",
    "\n",
    "# Tworzenie struktury folderÃ³w dla kaÅ¼dego modelu i wartoÅ›ci batch size\n",
    "for model_name in ['BalancedCNN', 'UnderfittingCNN', 'OverfittingCNN']:\n",
    "    for bs in batch_sizes:\n",
    "        folder_path = os.path.join(results_base_folder, f'{model_name}_bs_{bs}')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "print(\"Struktura folderÃ³w zostaÅ‚a przygotowana.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Funkcja treningowa z dynamicznym batch size\n",
    "def train_model(model, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, model_name, results_folder):\n",
    "    # Konfiguracja urzÄ…dzenia\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Dostosowanie DataLoader'Ã³w z dynamicznym batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Kryterium straty i optymalizator\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Listy do przechowywania wynikÃ³w\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    epoch_times = []\n",
    "\n",
    "    # PÄ™tla treningowa\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Walidacja\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Czas treningu jednej epoki\n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Zapis modelu po kaÅ¼dej epoce\n",
    "        torch.save(model.state_dict(), f'{results_folder}/model_epoch_{epoch+1}.pth')\n",
    "\n",
    "        # Zapis macierzy bÅ‚Ä™dÃ³w\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig(f'{results_folder}/confusion_matrix_epoch_{epoch+1}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Zapis raportu klasyfikacji\n",
    "        report = classification_report(all_labels, all_preds, zero_division=1)\n",
    "        with open(f'{results_folder}/classification_report_epoch_{epoch+1}.txt', 'w') as f:\n",
    "            f.write(report)\n",
    "\n",
    "    # Zapis wynikÃ³w do CSV\n",
    "    results = pd.DataFrame({\n",
    "        'Epoch': range(1, num_epochs + 1),\n",
    "        'Train Loss': train_losses,\n",
    "        'Train Accuracy': train_accuracies,\n",
    "        'Validation Loss': val_losses,\n",
    "        'Validation Accuracy': val_accuracies,\n",
    "        'Epoch Time': epoch_times\n",
    "    })\n",
    "    results.to_csv(f'{results_folder}/training_results.csv', index=False)\n",
    "\n",
    "    # Wykres przebiegu treningu\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{results_folder}/training_progress.png')\n",
    "    plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "balanced_model = BalancedCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych wartoÅ›ciach batch size\n",
    "for bs in batch_sizes:\n",
    "    print(f'\\nðŸ”µ Trening BalancedCNN z batch size = {bs}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_2/BalancedCNN_bs_{bs}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(balanced_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, bs, 'BalancedCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla UnderfittingCNN\n",
    "underfitting_model = UnderfittingCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych wartoÅ›ciach batch size\n",
    "for bs in batch_sizes:\n",
    "    print(f'\\nðŸŸ  Trening UnderfittingCNN z batch size = {bs}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_2/UnderfittingCNN_bs_{bs}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(underfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, bs, 'UnderfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla OverfittingCNN\n",
    "overfitting_model = OverfittingCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych wartoÅ›ciach batch size\n",
    "for bs in batch_sizes:\n",
    "    print(f'\\nðŸ”´ Trening OverfittingCNN z batch size = {bs}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_2/OverfittingCNN_bs_{bs}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(overfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, bs, 'OverfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperyment 3 â€“ PorÃ³wnanie optymalizatorÃ³w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BalancedCNN\n",
    "Adam lub RMSprop powinny zapewniÄ‡ najlepszÄ… rÃ³wnowagÄ™ miÄ™dzy stabilnoÅ›ciÄ… a szybkoÅ›ciÄ… uczenia.\n",
    "SGD moÅ¼e dziaÅ‚aÄ‡ poprawnie, ale wymaga optymalnego learning rate.\n",
    "\n",
    "UnderfittingCNN\n",
    "SGD lub Adagrad mogÄ… byÄ‡ dobrym wyborem ze wzglÄ™du na prostÄ… architekturÄ™ modelu.\n",
    "Adam moÅ¼e nieznacznie przyspieszyÄ‡ trening, ale niekoniecznie poprawi koÅ„cowe wyniki.\n",
    "\n",
    "OverfittingCNN\n",
    "AdamW lub RMSprop mogÄ… okazaÄ‡ siÄ™ kluczowe, aby utrzymaÄ‡ stabilnoÅ›Ä‡ gradientÃ³w w tym bardzo gÅ‚Ä™bokim modelu.\n",
    "SGD moÅ¼e dziaÅ‚aÄ‡ niestabilnie bez dodatkowych mechanizmÃ³w, takich jak momentum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struktura folderÃ³w zostaÅ‚a przygotowana.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ustawienia eksperymentu\n",
    "optimizers_to_test = ['Adam', 'SGD', 'RMSprop', 'Adagrad', 'AdamW']  # Testowane optymalizatory\n",
    "num_epochs = 20\n",
    "batch_size = 64  # StaÅ‚a wartoÅ›Ä‡ batch size, aby uniknÄ…Ä‡ wpÅ‚ywu innych zmiennych\n",
    "learning_rate = 0.001  # StaÅ‚a wartoÅ›Ä‡ learning rate\n",
    "\n",
    "# Foldery do zapisu wynikÃ³w\n",
    "results_base_folder = '../results/experiment_3'\n",
    "os.makedirs(results_base_folder, exist_ok=True)\n",
    "\n",
    "# Tworzenie struktury folderÃ³w dla kaÅ¼dego modelu i optymalizatora\n",
    "for model_name in ['BalancedCNN', 'UnderfittingCNN', 'OverfittingCNN']:\n",
    "    for optimizer_name in optimizers_to_test:\n",
    "        folder_path = os.path.join(results_base_folder, f'{model_name}_{optimizer_name}')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "print(\"Struktura folderÃ³w zostaÅ‚a przygotowana.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Funkcja treningowa z dynamicznym wyborem optymalizatora\n",
    "def train_model(model, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, optimizer_name, model_name, results_folder):\n",
    "    # Konfiguracja urzÄ…dzenia\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Dostosowanie DataLoader'Ã³w\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Kryterium straty\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # WybÃ³r optymalizatora na podstawie argumentu\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name == 'Adagrad':\n",
    "        optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name == 'AdamW':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Nieznany optymalizator: {optimizer_name}\")\n",
    "\n",
    "    # Listy do przechowywania wynikÃ³w\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    epoch_times = []\n",
    "\n",
    "    # PÄ™tla treningowa\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Walidacja\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Czas treningu jednej epoki\n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        print(f'{model_name} - {optimizer_name} - Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Zapis modelu po kaÅ¼dej epoce\n",
    "        torch.save(model.state_dict(), f'{results_folder}/model_epoch_{epoch+1}.pth')\n",
    "\n",
    "        # Zapis macierzy bÅ‚Ä™dÃ³w\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig(f'{results_folder}/confusion_matrix_epoch_{epoch+1}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Zapis raportu klasyfikacji\n",
    "        report = classification_report(all_labels, all_preds, zero_division=1)\n",
    "        with open(f'{results_folder}/classification_report_epoch_{epoch+1}.txt', 'w') as f:\n",
    "            f.write(report)\n",
    "\n",
    "    # Zapis wynikÃ³w do CSV\n",
    "    results = pd.DataFrame({\n",
    "        'Epoch': range(1, num_epochs + 1),\n",
    "        'Train Loss': train_losses,\n",
    "        'Train Accuracy': train_accuracies,\n",
    "        'Validation Loss': val_losses,\n",
    "        'Validation Accuracy': val_accuracies,\n",
    "        'Epoch Time': epoch_times\n",
    "    })\n",
    "    results.to_csv(f'{results_folder}/training_results.csv', index=False)\n",
    "\n",
    "    # Wykres przebiegu treningu\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{results_folder}/training_progress.png')\n",
    "    plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "balanced_model = BalancedCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych optymalizatorach\n",
    "for optimizer_name in optimizers_to_test:\n",
    "    print(f'\\nðŸ”µ Trening BalancedCNN z optymalizatorem = {optimizer_name}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_3/BalancedCNN_{optimizer_name}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(balanced_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, optimizer_name, 'BalancedCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla UnderfittingCNN\n",
    "underfitting_model = UnderfittingCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych optymalizatorach\n",
    "for optimizer_name in optimizers_to_test:\n",
    "    print(f'\\nðŸŸ  Trening UnderfittingCNN z optymalizatorem = {optimizer_name}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_3/UnderfittingCNN_{optimizer_name}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(underfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, optimizer_name, 'UnderfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla OverfittingCNN\n",
    "overfitting_model = OverfittingCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych optymalizatorach\n",
    "for optimizer_name in optimizers_to_test:\n",
    "    print(f'\\nðŸ”´ Trening OverfittingCNN z optymalizatorem = {optimizer_name}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_3/OverfittingCNN_{optimizer_name}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(overfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, optimizer_name, 'OverfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperyment 4 â€“ Badanie rÃ³Å¼nych metod regularyzacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipotezy\n",
    "BalancedCNN\n",
    "Dropout i Batch Normalization powinny zapewniÄ‡ dobrÄ… rÃ³wnowagÄ™ miÄ™dzy stabilnoÅ›ciÄ… a skutecznoÅ›ciÄ….\n",
    "L2 Regularization moÅ¼e dodatkowo poprawiÄ‡ generalizacjÄ™.\n",
    "\n",
    "UnderfittingCNN\n",
    "Batch Normalization powinno poprawiÄ‡ stabilnoÅ›Ä‡, natomiast Dropout moÅ¼e spowolniÄ‡ konwergencjÄ™.\n",
    "Early Stopping moÅ¼e byÄ‡ skuteczne przy prostym modelu, gdyÅ¼ ograniczy niepotrzebne epoki.\n",
    "\n",
    "OverfittingCNN\n",
    "Dropout oraz L2 Regularization bÄ™dÄ… kluczowe w redukcji przeuczenia.\n",
    "Batch Normalization oraz Layer Normalization mogÄ… poprawiÄ‡ stabilnoÅ›Ä‡ gradientÃ³w przy bardzo gÅ‚Ä™bokiej architekturze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struktura folderÃ³w zostaÅ‚a przygotowana.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ustawienia eksperymentu\n",
    "regularization_methods = ['Dropout', 'BatchNorm', 'L2_Regularization', 'EarlyStopping', 'LayerNorm']\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "learning_rate = 0.001  # StaÅ‚a wartoÅ›Ä‡ learning rate\n",
    "\n",
    "# Foldery do zapisu wynikÃ³w\n",
    "results_base_folder = '../results/experiment_4'\n",
    "os.makedirs(results_base_folder, exist_ok=True)\n",
    "\n",
    "# Tworzenie struktury folderÃ³w dla kaÅ¼dego modelu i metody regularyzacji\n",
    "for model_name in ['BalancedCNN', 'UnderfittingCNN', 'OverfittingCNN']:\n",
    "    for reg_method in regularization_methods:\n",
    "        folder_path = os.path.join(results_base_folder, f'{model_name}_{reg_method}')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "print(\"Struktura folderÃ³w zostaÅ‚a przygotowana.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Funkcja treningowa z dynamicznym wyborem metody regularyzacji\n",
    "def train_model(model, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, reg_method, model_name, results_folder):\n",
    "    # Konfiguracja urzÄ…dzenia\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Dostosowanie DataLoader'Ã³w\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Kryterium straty\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optymalizator (Adam dla spÃ³jnoÅ›ci z wczeÅ›niejszymi eksperymentami)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Dodanie regularyzacji do modelu na podstawie wyboru\n",
    "    if reg_method == 'Dropout':\n",
    "        model.fc_layers.add_module(\"Dropout\", nn.Dropout(0.4))\n",
    "    elif reg_method == 'BatchNorm':\n",
    "        for layer in model.conv_layers:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                model.conv_layers.add_module(f\"BatchNorm_{layer.out_channels}\", nn.BatchNorm2d(layer.out_channels))\n",
    "    elif reg_method == 'L2_Regularization':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    elif reg_method == 'EarlyStopping':\n",
    "        early_stopping = True\n",
    "        best_loss = float('inf')\n",
    "        patience = 3  # Wczesne zatrzymanie po 3 epokach bez poprawy\n",
    "        patience_counter = 0\n",
    "    elif reg_method == 'LayerNorm':\n",
    "        for layer in model.fc_layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                model.fc_layers.add_module(f\"LayerNorm_{layer.out_features}\", nn.LayerNorm(layer.out_features))\n",
    "    else:\n",
    "        raise ValueError(f\"Nieznana metoda regularyzacji: {reg_method}\")\n",
    "\n",
    "    # Listy do przechowywania wynikÃ³w\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    epoch_times = []\n",
    "\n",
    "    # PÄ™tla treningowa\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Walidacja\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Wczesne zatrzymanie (Early Stopping)\n",
    "        if reg_method == 'EarlyStopping':\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f'Wczesne zatrzymanie treningu po {epoch + 1} epokach.')\n",
    "                    break\n",
    "\n",
    "        # Czas treningu jednej epoki\n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        print(f'{model_name} - {reg_method} - Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Zapis modelu po kaÅ¼dej epoce\n",
    "        torch.save(model.state_dict(), f'{results_folder}/model_epoch_{epoch+1}.pth')\n",
    "\n",
    "        # Zapis macierzy bÅ‚Ä™dÃ³w\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig(f'{results_folder}/confusion_matrix_epoch_{epoch+1}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Zapis raportu klasyfikacji\n",
    "        report = classification_report(all_labels, all_preds, zero_division=1)\n",
    "        with open(f'{results_folder}/classification_report_epoch_{epoch+1}.txt', 'w') as f:\n",
    "            f.write(report)\n",
    "\n",
    "    # Zapis wynikÃ³w do CSV\n",
    "    results = pd.DataFrame({\n",
    "        'Epoch': range(1, num_epochs + 1),\n",
    "        'Train Loss': train_losses,\n",
    "        'Train Accuracy': train_accuracies,\n",
    "        'Validation Loss': val_losses,\n",
    "        'Validation Accuracy': val_accuracies,\n",
    "        'Epoch Time': epoch_times\n",
    "    })\n",
    "    results.to_csv(f'{results_folder}/training_results.csv', index=False)\n",
    "\n",
    "    # Wykres przebiegu treningu\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.title(f'{model_name} - {reg_method} - Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{results_folder}/training_progress.png')\n",
    "    plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "balanced_model = BalancedCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych metodach regularyzacji\n",
    "for reg_method in regularization_methods:\n",
    "    print(f'\\nðŸ”µ Trening BalancedCNN z regularyzacjÄ… = {reg_method}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_4/BalancedCNN_{reg_method}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(balanced_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, reg_method, 'BalancedCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla UnderfittingCNN\n",
    "underfitting_model = UnderfittingCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych metodach regularyzacji\n",
    "for reg_method in regularization_methods:\n",
    "    print(f'\\nðŸŸ  Trening UnderfittingCNN z regularyzacjÄ… = {reg_method}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_4/UnderfittingCNN_{reg_method}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(underfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, reg_method, 'UnderfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla OverfittingCNN\n",
    "overfitting_model = OverfittingCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych metodach regularyzacji\n",
    "for reg_method in regularization_methods:\n",
    "    print(f'\\nðŸ”´ Trening OverfittingCNN z regularyzacjÄ… = {reg_method}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_4/OverfittingCNN_{reg_method}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(overfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, reg_method, 'OverfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperyment 5 â€“ Analiza wpÅ‚ywu augmentacji danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BalancedCNN\n",
    "Random Crop i Random Flip powinny poprawiÄ‡ zdolnoÅ›Ä‡ modelu do rozpoznawania danych wejÅ›ciowych w rÃ³Å¼nych pozycjach.\n",
    "\n",
    "UnderfittingCNN\n",
    "Color Jitter i Gaussian Noise mogÄ… poprawiÄ‡ odpornoÅ›Ä‡ prostego modelu na znieksztaÅ‚cenia danych.\n",
    "\n",
    "OverfittingCNN\n",
    "Random Rotation oraz Random Crop mogÄ… znaczÄ…co poprawiÄ‡ generalizacjÄ™ modelu, ktÃ³ry ma tendencjÄ™ do przeuczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struktura folderÃ³w zostaÅ‚a przygotowana.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ustawienia eksperymentu\n",
    "augmentation_methods = ['RandomCrop', 'RandomFlip', 'ColorJitter', 'GaussianNoise', 'RandomRotation']\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "learning_rate = 0.001  # StaÅ‚a wartoÅ›Ä‡ learning rate\n",
    "\n",
    "# Foldery do zapisu wynikÃ³w\n",
    "results_base_folder = '../results/experiment_5'\n",
    "os.makedirs(results_base_folder, exist_ok=True)\n",
    "\n",
    "# Tworzenie struktury folderÃ³w dla kaÅ¼dego modelu i techniki augmentacji\n",
    "for model_name in ['BalancedCNN', 'UnderfittingCNN', 'OverfittingCNN']:\n",
    "    for aug_method in augmentation_methods:\n",
    "        folder_path = os.path.join(results_base_folder, f'{model_name}_{aug_method}')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "print(\"Struktura folderÃ³w zostaÅ‚a przygotowana.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Funkcja augmentacji danych na podstawie wybranej metody\n",
    "def get_augmentation(aug_method):\n",
    "    if aug_method == 'RandomCrop':\n",
    "        return transforms.RandomCrop((56, 56))  # PrzyciÄ™cie obrazu do 56x56 z losowÄ… lokalizacjÄ…\n",
    "    elif aug_method == 'RandomFlip':\n",
    "        return transforms.RandomHorizontalFlip(p=0.5)  # Losowe odbicie poziome\n",
    "    elif aug_method == 'ColorJitter':\n",
    "        return transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)  \n",
    "    elif aug_method == 'GaussianNoise':\n",
    "        return transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.05),  # Szum gaussowski\n",
    "            transforms.ToPILImage()\n",
    "        ])\n",
    "    elif aug_method == 'RandomRotation':\n",
    "        return transforms.RandomRotation(30)  # Losowy obrÃ³t o Â±30Â°\n",
    "    else:\n",
    "        raise ValueError(f\"Nieznana metoda augmentacji: {aug_method}\")\n",
    "\n",
    "# Funkcja treningowa z dynamicznym wyborem augmentacji\n",
    "def train_model(model, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, aug_method, model_name, results_folder):\n",
    "    # Konfiguracja urzÄ…dzenia\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Dostosowanie augmentacji do danych treningowych\n",
    "    train_transform = transforms.Compose([\n",
    "        get_augmentation(aug_method),\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Walidacja pozostaje bez augmentacji\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Stworzenie nowych zestawÃ³w danych z odpowiednimi transformacjami\n",
    "    train_dataset.transform = train_transform\n",
    "    val_dataset.transform = val_transform\n",
    "\n",
    "    # Dostosowanie DataLoader'Ã³w\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Kryterium straty i optymalizator\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Listy do przechowywania wynikÃ³w\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    epoch_times = []\n",
    "\n",
    "    # PÄ™tla treningowa\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Walidacja\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Czas treningu jednej epoki\n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        print(f'{model_name} - {aug_method} - Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Zapis modelu po kaÅ¼dej epoce\n",
    "        torch.save(model.state_dict(), f'{results_folder}/model_epoch_{epoch+1}.pth')\n",
    "\n",
    "    # Zapis wynikÃ³w do CSV\n",
    "    results = pd.DataFrame({\n",
    "        'Epoch': range(1, num_epochs + 1),\n",
    "        'Train Loss': train_losses,\n",
    "        'Train Accuracy': train_accuracies,\n",
    "        'Validation Loss': val_losses,\n",
    "        'Validation Accuracy': val_accuracies,\n",
    "        'Epoch Time': epoch_times\n",
    "    })\n",
    "    results.to_csv(f'{results_folder}/training_results.csv', index=False)\n",
    "\n",
    "    # Wykres przebiegu treningu\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.title(f'{model_name} - {aug_method} - Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{results_folder}/training_progress.png')\n",
    "    plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "balanced_model = BalancedCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych technikach augmentacji\n",
    "for aug_method in augmentation_methods:\n",
    "    print(f'\\nðŸ”µ Trening BalancedCNN z augmentacjÄ… = {aug_method}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_5/BalancedCNN_{aug_method}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(balanced_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, aug_method, 'BalancedCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla UnderfittingCNN\n",
    "underfitting_model = UnderfittingCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych technikach augmentacji\n",
    "for aug_method in augmentation_methods:\n",
    "    print(f'\\nðŸŸ  Trening UnderfittingCNN z augmentacjÄ… = {aug_method}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_5/UnderfittingCNN_{aug_method}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(underfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, aug_method, 'UnderfittingCNN', results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchomienie treningu dla OverfittingCNN\n",
    "overfitting_model = OverfittingCNN()\n",
    "\n",
    "# PÄ™tla po rÃ³Å¼nych technikach augmentacji\n",
    "for aug_method in augmentation_methods:\n",
    "    print(f'\\nðŸ”´ Trening OverfittingCNN z augmentacjÄ… = {aug_method}')\n",
    "    \n",
    "    # ÅšcieÅ¼ka zapisu wynikÃ³w\n",
    "    results_folder = f'../results/experiment_5/OverfittingCNN_{aug_method}'\n",
    "    \n",
    "    # Kopia modelu dla unikniÄ™cia nadpisania wag\n",
    "    model_copy = deepcopy(overfitting_model)\n",
    "    \n",
    "    # Trening modelu\n",
    "    train_model(model_copy, train_dataset, val_dataset, num_epochs, learning_rate, batch_size, aug_method, 'OverfittingCNN', results_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
